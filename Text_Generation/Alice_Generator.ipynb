{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b1e2b5d",
   "metadata": {},
   "source": [
    "1. 数据集准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d505fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打开并读取文本文件\n",
    "with open('alice_in_wonderland.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2acefa01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text length: 141518\n"
     ]
    }
   ],
   "source": [
    "print('Text length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44bdc7a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\u3000\\u3000\\n\\n\\u3000\\u3000ALICE'S ADVENTURES IN WONDERLAND\\n\\n\\u3000\\u3000Lewis Carroll\\n\\n\\u3000\\u3000CHAPTER I\\n\\n\\u3000\\u3000Down the Rabbit-Hole\\n\\n\\u3000\\u3000Alice was beginning to get very tired of sitting by her sisteron the bank, and of having nothing to do:  once or twice she hadpeeped into the book her sister was reading, but it had nopictures or conversations in it, `and what is the use of a book,'thought Alice `without pictures or conversation?'So she was considering in her own mind (as well as she could,for the hot day made her feel very sleepy and stupid), whetherthe pleasure of making a daisy-chain would be worth the troubleof getting up and picking the daisies, when suddenly a WhiteRabbit with pink eyes ran close by her.There was nothing so VERY remarkable in that; nor did Alicethink it so VERY much out of the way to hear the Rabbit say toitself, `Oh dear!  Oh dear!  I shall be late!'  (when she thoughtit over afterwards, it occurred to her that she ought to havewondered at this, but at the time it all seemed quite natural);but when th\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "990d93f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化两个列表\n",
    "segments = []  # 用于存储长度为60的字符片段\n",
    "next_chars = []  # 用于存储对应的下一个字符\n",
    "\n",
    "# 设置步长和片段长度\n",
    "step = 3\n",
    "sequence_length = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2c4953a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 47153\n",
      "Example segment: r sisteron the bank, and of having nothing to do:  once or t\n",
      "Example next char: w\n"
     ]
    }
   ],
   "source": [
    "# 遍历文本，提取片段和对应的下一个字符\n",
    "for i in range(0, len(text) - sequence_length, step):\n",
    "    # 提取长度为60的字符片段\n",
    "    segment = text[i:i + sequence_length]\n",
    "    # 提取对应的下一个字符\n",
    "    next_char = text[i + sequence_length]\n",
    "    # 将片段和下一个字符分别添加到对应的列表中\n",
    "    segments.append(segment)\n",
    "    next_chars.append(next_char)\n",
    "\n",
    "# 打印部分结果，用于验证\n",
    "print(f\"Number of sequences: {len(segments)}\")\n",
    "print(f\"Example segment: {segments[50]}\")\n",
    "print(f\"Example next char: {next_chars[50]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b202b574",
   "metadata": {},
   "source": [
    "2. Character to Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cab2816",
   "metadata": {},
   "source": [
    "不需要Word Embedding，这是因为之前用的是word level tokenization，常用英文单词有10000个，one-hot向量维度太高了，所以要用word embedding降维为低维词向量；但做文本生成是character level tokenization，使用的字符只有几十一百个，维度不高。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f20d0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50732350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建字符字典\n",
    "chars = sorted(list(set(text)))  # 获取所有唯一字符\n",
    "char_to_index = {char: index for index, char in enumerate(chars)}  # 字符到索引的映射\n",
    "index_to_char = {index: char for index, char in enumerate(chars)}  # 索引到字符的映射"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8507dc42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_chars=len(char_to_index)\n",
    "num_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "341f068a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sequences=len(segments)\n",
    "# 初始化输入矩阵和目标向量\n",
    "X = np.zeros((num_sequences, sequence_length, num_chars), dtype=np.bool)  # 输入矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6096034a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.zeros((num_sequences, num_chars), dtype=np.bool)  # 目标向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fab1132c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example input sequence (One-Hot encoded):\n",
      "[[False False False ... False False False]\n",
      " [False  True False ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False  True False ... False False False]\n",
      " [False False False ... False False False]]\n",
      "Example target character (One-Hot encoded):\n",
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False  True False False False False]\n"
     ]
    }
   ],
   "source": [
    "# 填充输入矩阵和目标向量\n",
    "for i, segment in enumerate(segments):\n",
    "    for t, char in enumerate(segment):\n",
    "        X[i, t, char_to_index[char]] = 1  # One-Hot 编码\n",
    "    y[i, char_to_index[next_chars[i]]] = 1  # One-Hot 编码\n",
    "\n",
    "# 打印部分结果，用于验证\n",
    "print(f\"Example input sequence (One-Hot encoded):\")\n",
    "print(X[50])\n",
    "print(f\"Example target character (One-Hot encoded):\")\n",
    "print(y[50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b390ec0c",
   "metadata": {},
   "source": [
    "3. build a NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38617add",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6e6fcb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">102,400</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">71</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">9,159</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m102,400\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m71\u001b[0m)                  │           \u001b[38;5;34m9,159\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,559</span> (435.78 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m111,559\u001b[0m (435.78 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,559</span> (435.78 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m111,559\u001b[0m (435.78 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(sequence_length,num_chars)), # 输入60x71 片段长度60，one-hot向量 71维\n",
    "    LSTM(128), # 状态向量的维度：128\n",
    "    Dense(num_chars, activation=\"softmax\") # 全连接层输出71维，使用softmax激活函数生成概率分布\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4ffbd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optimizers.RMSprop(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d5eec03",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddffa333",
   "metadata": {},
   "source": [
    "4. 训练神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75e4b7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 55ms/step - loss: 2.8125\n",
      "Epoch 2/5\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 54ms/step - loss: 1.9719\n",
      "Epoch 3/5\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 54ms/step - loss: 1.7496\n",
      "Epoch 4/5\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 54ms/step - loss: 1.6083\n",
      "Epoch 5/5\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 53ms/step - loss: 1.4793\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1f46c71d1f0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, batch_size=128, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b86afc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"alice_generator.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081cd419",
   "metadata": {},
   "source": [
    "预测下一个字符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74bb455f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_with_temperature(preds, temperature=1.0):\n",
    "    \"\"\"\n",
    "    根据温度参数从预测的概率分布中选择字符\n",
    "    :param preds: 模型预测的概率分布\n",
    "    :param temperature: 温度参数，控制生成的多样性\n",
    "    :return: 选择的字符索引\n",
    "    \"\"\"\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    # 公式1：调整概率分布的锐度\n",
    "    preds = preds ** (1 / temperature)\n",
    "    # 公式2：归一化概率分布\n",
    "    preds = preds / np.sum(preds)\n",
    "    \n",
    "    # 从调整后的概率分布中随机选择字符\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb52b97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义文本生成函数\n",
    "def generate_text(model, seed_text, length=400, temperature=0.5):\n",
    "    generated = ''\n",
    "    generated += seed_text\n",
    "    sentence = seed_text\n",
    "\n",
    "    for i in range(length):\n",
    "        x_pred = np.zeros((1, sequence_length, num_chars))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_to_index[char]] = 1\n",
    "\n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        next_index = sample_with_temperature(preds, temperature)\n",
    "        next_char = index_to_char[next_index]\n",
    "\n",
    "        generated += next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff468fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 准备种子文本\n",
    "seed_text = \"Alice was captured by Queen when the rabbit says: `why do cr\"\n",
    "len(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e382742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.05739083e-05, 3.05844995e-04, 4.69993647e-05, 4.53846906e-06,\n",
       "       4.09607719e-06, 4.17648198e-06, 3.88996341e-06, 3.11852114e-06,\n",
       "       8.10987258e-05, 1.26622954e-05, 3.94520575e-05, 3.85735220e-05,\n",
       "       1.04751516e-05, 7.66049998e-05, 4.96368040e-04, 2.97916231e-05,\n",
       "       1.78040555e-05, 6.07294896e-05, 1.22988538e-04, 8.10615802e-06,\n",
       "       3.41269952e-05, 2.03033182e-04, 1.55877133e-04, 4.59129251e-06,\n",
       "       1.10423771e-05, 8.92318349e-05, 8.66631453e-05, 2.77621904e-04,\n",
       "       7.29588326e-04, 2.82847705e-05, 1.14942413e-05, 1.01993253e-04,\n",
       "       7.54460489e-05, 9.49585374e-05, 2.05365068e-04, 1.45691829e-05,\n",
       "       2.41421476e-05, 5.93641971e-06, 1.20172284e-04, 7.50842582e-06,\n",
       "       6.50267430e-06, 3.99120654e-06, 5.26177428e-06, 3.53123978e-05,\n",
       "       5.02086133e-02, 5.69160002e-05, 1.44778924e-05, 8.35243839e-07,\n",
       "       2.99240619e-01, 9.93505364e-06, 1.24537346e-05, 6.25295856e-04,\n",
       "       3.86385500e-01, 6.49239882e-05, 1.99518436e-05, 2.85638584e-04,\n",
       "       5.99894323e-04, 6.00735017e-04, 1.49291143e-01, 2.16414905e-04,\n",
       "       1.16584873e-04, 3.50060611e-04, 1.15131486e-04, 1.45445083e-04,\n",
       "       1.01638854e-01, 2.21541668e-05, 4.13202906e-05, 2.87452235e-06,\n",
       "       6.16481714e-03, 2.66994321e-05, 2.11661313e-06], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试生成下一个字符\n",
    "X_in = np.zeros((1, 60, num_chars), dtype=np.bool)  # 输入矩阵\n",
    "for t, char in enumerate(seed_text):\n",
    "    X_in[0, t, char_to_index[char]] = 1\n",
    "\n",
    "preds = model.predict(X_in, verbose=0)[0] # verbose=0表示不输出日志信息，[0]是因为输出的第一维是bitch size\n",
    "\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8a52a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_index = sample_with_temperature(preds, temperature=0.5)\n",
    "next_char = index_to_char[next_index]\n",
    "next_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0c88faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text:\n",
      "Alice was captured by Queen when the rabbit says: `why do cried the same said the was ot the tood her sist and the gat of the Hatter went on the to see the face.`What you cale the great dreat breet to be the same wittle of her been a was a got to leaved repted to hard again.`I'll you thing I sit!' he did not she to do upened the was the was the was of the formout the gat of the was the long at the reat on the thing of it out the gat of the words the more o\n"
     ]
    }
   ],
   "source": [
    "# 生成文本1\n",
    "generated_text = generate_text(model, seed_text, length=400, temperature=0.5)\n",
    "print(\"Generated Text:\")\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d8cb338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text:\n",
      "Alice was captured by Queen when the rabbit says: `why do cried the same been a nittle was the rept of the long and the same as she was the court, and was the tried to herself and the long and was the time she was not a little had for first this said to herself and she was the reat of the was on the same to lear her at the same and the was on the game again.`I with her so cause it as she was to herself to her her head of the was the other seepting to herse\n"
     ]
    }
   ],
   "source": [
    "# 生成文本1\n",
    "generated_text = generate_text(model, seed_text, length=400, temperature=0.3)\n",
    "print(\"Generated Text:\")\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dfc1da17",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_text2 = \"Alice was beginning to get very tired of sitting by her sist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "88da2158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text:\n",
      "Alice was beginning to get very tired of sitting by her sister the on the to see found her her head it was the had had for she spilled at the Caterpillar of the long of the gaterpillar to her a thing the door of the gating to her her hear her sister while the gat of the game of the at her finish and the rest of the ratter of the tried.`I'm a great be a ground of the matter sisterplied to herself was the one of the gater the same been a little a began inthe\n"
     ]
    }
   ],
   "source": [
    "# 生成文本2\n",
    "generated_text = generate_text(model, seed_text2, length=400, temperature=0.3)\n",
    "print(\"Generated Text:\")\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5fa3a15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text:\n",
      "Alice was beginning to get very tired of sitting by her sister her here without of the Rabbit was the was not to like a the sway of the moment had faning oneer the rest hard.  `She parious at a must a mind, and the crowers, and she was the got of the get arden about at a little firit out the reat of the ratter little first again, and the sent of the reppining to herself and the ormouse again, and she had was a get inthe back inthe now, and the sea.'`I'm th\n"
     ]
    }
   ],
   "source": [
    "# 生成文本2\n",
    "generated_text = generate_text(model, seed_text2, length=400, temperature=0.5)\n",
    "print(\"Generated Text:\")\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fe8fc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
