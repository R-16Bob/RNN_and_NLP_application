此仓库的目的是对NLP以及Transformer进行学习与实践，因为这些是大模型的基础。内容是B站[ShusenWang](https://space.bilibili.com/1369507485)老师的课程[RNN模型与NLP应用](https://www.bilibili.com/video/BV1w54y1L7xK?spm_id_from=333.788.videopod.sections&vd_source=e63f08e3795a7d51a7cfc6c0294d87ee) 的笔记。我使用jupyter notebook实践了其中提出的模型。

# 目录
## 1. [NLP基础：文本处理与词嵌入](Preliminaries/NLP基础：文本处理与词嵌入.md)
## 2. [Simple RNN](RNN/Simple_RNN.md) 
## 3. [LSTM](LSTM/Long_Short_Term_Memory.md)
## 4. [Making RNNs more effective](More_effective_RNN/Making_RNNs_more_effective.md)
## 5. [Text_Generation](Text_Generation/Text_Generation.md)
## 6. [Machine Traslation and Seq2Seq](Seq2Seq/Seq2Seq.md)
## 7. [Attention](Attention/Attention.md)
## 8. [Self-Attention](Attention/Self_Attention.md)
## 9. [Transformer_Part1: Attention layer & Self-Attention layer](Transformer/Transformer_Part1.md)
## 10. [Transformer Part 2: From Shallow to Deep](Transformer/Transformer_Part2.md)
## 11. [BERT](BERT/BERT.md)
